---
title: "Intraday"
output: pdf_document
date: "2024-05-27"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load Libraries
```{r}
library(tidyverse)
library(lubridate)
library(forecast)
library(tseries)
library(Metrics)
library(zoo)
```


## Load and Process Data
Subset to full weeks in 2024. Remove data for non-trading hours to avoid complexities with dealing with seasonality across the 5 trading days in a week but no volumes over weekends.
```{r}
df <- read.csv('SPY_intraday.csv')
vol <- df#[c('timestamp', 'volume', 'close')]
vol$timestamp <- as.POSIXct(vol$timestamp, format = "%Y-%m-%d %H:%M:%S")
vol$timestamp <- vol$timestamp - hours(3)

# Rename columns
names(vol)[names(vol) == 'volume'] <- 'Volume'
names(vol)[names(vol) == 'timestamp'] <- 'Timestamp'

# Subset Data
start_date = "2024-01-08"
end_date = "2024-05-16"
vol = vol[vol$Timestamp >= start_date,]
vol = vol[vol$Timestamp <= end_date,]


# Define 24 hours per day and volume = 0 for each time with no trading
start_date <- as.Date(min(vol$Timestamp))
end_date <- as.Date(max(vol$Timestamp))
all_hours <- seq.POSIXt(as.POSIXct(paste(start_date, "00:00:00")), 
                        as.POSIXct(paste(end_date, "23:00:00")), 
                        by = "hour")
full_data <- data.frame(Timestamp = all_hours) %>%
  left_join(vol, by = "Timestamp") %>%
  replace_na(list(Volume = 0))

vol <- full_data


# Define separate date and time columns
vol$Date <- as.Date(vol$Timestamp, origin = "1904-01-01", tz = "PST8PDT")
vol$Time <- format(vol$Timestamp,"%H:%M:%S")


# Remove 3/10/24 due to complications with attributing time due to daylight savings
vol = vol[vol$Date != "2024-03-10",]


# Extract Trading Hours data only
trading_hours <- vol %>%
  filter(wday(Timestamp, week_start = 1) %in% 1:5 & 
         ((hour(Timestamp) == 9) | 
          (hour(Timestamp) > 9 & hour(Timestamp) < 16) | 
          (hour(Timestamp) == 16)))

# Remove Holidays
trading_hours = trading_hours[trading_hours$Date != '2024-01-15',]
trading_hours = trading_hours[trading_hours$Date != '2024-02-19',]
trading_hours = trading_hours[trading_hours$Date != '2024-03-29',]
trading_hours = trading_hours[trading_hours$Date != '2024-05-16',]


plot(trading_hours$Volume, type = 'l')
```



## EDA
Volume spikes in first couple hours of trading, then dies down, then again spikes at the close.

Strong seasonality component every 8 timesteps (daily).
```{r}
# Plot Data (Incl Weekends/Non-trading Hours)
start_date = "2024-01-01" # SUBSETS ONLY FOR PLOT!!!
subsetvol = vol[vol$Timestamp >= start_date,]
plot(subsetvol$Timestamp, subsetvol$Volume, type = 'l', main = 'SPY Intraday Trading Volume 2024')




# Average hourly trading volume
avghourlyvolume <- vol %>%
                      group_by(Time) %>%
                      summarise(avgvol = mean(Volume),
                                sdvol = sd(Volume))

avghourlyvolume$Time <- as.POSIXct(avghourlyvolume$Time, format = "%H:%M:%S")


U = avghourlyvolume$avgvol + avghourlyvolume$sdvol
L = avghourlyvolume$avgvol - avghourlyvolume$sdvol

plot(avghourlyvolume$Time, avghourlyvolume$avgvol, type = 'l',
     xlim=as.POSIXct(c("2024-05-27 9:00:00","2024-05-27 18:00:00")),
     ylim=c(0, 23000000),
     main = "Average Hourly Trading Volume",
     xlab = "Time of Day",
     ylab = "Volume")
points(avghourlyvolume$Time, U, col = "red", type = "l")
points(avghourlyvolume$Time, L, col = "red", type = "l")
abline(v=as.POSIXct(c("2024-05-27 9:30:00", "2024-05-27 16:00:00")), col="blue")




# ACF/PACF plots
acf(trading_hours$Volume, main = "ACF Plot - Intraday Volume")
pacf(trading_hours$Volume, main = "Partial ACF Plot - Intraday Volume")


# Convert to time series - frequency is weekly because of issues that arise due to no trading on weekends if freq = 24
ts_data <- ts(trading_hours$Volume, frequency = 8)

# Decompose Time Series
decomp <- decompose(ts_data)
plot(decomp)

```



## Model Fitting -- ARIMA()
Strong seasonality component that repeats every 8 hours (daily)
```{r}
# Diagnosis Plots Raw
acf(trading_hours$Volume)
pacf(trading_hours$Volume)

# Diagnosis Plots w/Seasonal Differencing
acf(diff(trading_hours$Volume, lag=8, differences=1))
pacf(diff(trading_hours$Volume, lag=8, differences=1))

# Fit best ARIMA model
fit <- auto.arima(ts_data, seasonal = TRUE)
summary(fit)

residuals <- fit$residuals
plot(residuals)
checkresiduals(fit)

# Forecast
forecast_values <- forecast(fit, h=16)
plot(forecast_values)
```


### Predicting Using ARIMA Model
#####  ARIMA(1, 0, 2)(0, 1, 2)
One potential model given the EDA
```{r}
# Define training and test periods
train_start_date <- as.Date("2024-01-08")
test_start_date <- as.Date("2024-05-01")
test_end_date <- as.Date("2024-05-15")

# Define dates to loop through in testing
dates <- trading_hours$Date[trading_hours$Date >= test_start_date & trading_hours$Date <= test_end_date]
dates <- dates[!duplicated(dates)]

# Initialize lists to store results
mse_list <- list()
mape_list <- list()
forecasts <- list()
actuals <- list()

# Loop through each test date
for (test_date in dates) {
  # Define training data
  train_data <- trading_hours %>% filter(Date < test_date)
  ts_train <- ts(train_data$Volume, frequency = 8)
  
  # Fit ARIMA model on training data
  fit <- arima(ts_train, order = c(1, 0, 2), seasonal = c(0, 1, 2))
  summary(fit)
  checkresiduals(fit)
  
  # Forecast for the test date (8 trading hours)
  forecast_values <- forecast(fit, h = 8)
  
  # Extract actual values for the test date
  actual_values <- trading_hours %>%
    filter(Date == test_date) %>%
    select(Volume) %>%
    unlist()
  
  # Calculate MSE and MAPE
  mse_value <- mse(actual_values, forecast_values$mean)
  mape_value <- mape(actual_values, forecast_values$mean)
  
  # Store results in list
  mse_list[[as.character(test_date)]] <- mse_value
  mape_list[[as.character(test_date)]] <- mape_value
  forecasts[[as.character(test_date)]] <- forecast_values
  actuals[[as.character(test_date)]] <- actual_values

}

# Calculate average MSE and MAPE across all predictions
avg_mse <- mean(unlist(mse_list))
avg_mape <- mean(unlist(mape_list))

cat("Average MSE:", avg_mse, "\n")
cat("Average MAPE:", avg_mape, "\n")
```

#####  ARIMA(1, 0, 3)(0, 1, 2)
Another potential model given the EDA
```{r}
# Define training and test periods
train_start_date <- as.Date("2024-01-08")
test_start_date <- as.Date("2024-05-01")
test_end_date <- as.Date("2024-05-15")

# Define dates to loop through in testing
dates <- trading_hours$Date[trading_hours$Date >= test_start_date & trading_hours$Date <= test_end_date]
dates <- dates[!duplicated(dates)]

# Initialize lists to store results
mse_list <- list()
mape_list <- list()
forecasts <- list()
actuals <- list()

# Loop through each test date
for (test_date in dates) {
  # Define training data
  train_data <- trading_hours %>% filter(Date < test_date)
  ts_train <- ts(train_data$Volume, frequency = 8)
  
  # Fit ARIMA model on training data
  fit <- arima(ts_train, order = c(1, 0, 3), seasonal = c(0, 1, 2))
  summary(fit)
  checkresiduals(fit)
  
  # Forecast for the test date (8 trading hours)
  forecast_values <- forecast(fit, h = 8)
  
  # Extract actual values for the test date
  actual_values <- trading_hours %>%
    filter(Date == test_date) %>%
    select(Volume) %>%
    unlist()
  
  # Calculate MSE and MAPE
  mse_value <- mse(actual_values, forecast_values$mean)
  mape_value <- mape(actual_values, forecast_values$mean)
  
  # Store results in list
  mse_list[[as.character(test_date)]] <- mse_value
  mape_list[[as.character(test_date)]] <- mape_value
  forecasts[[as.character(test_date)]] <- forecast_values
  actuals[[as.character(test_date)]] <- actual_values

}

# Calculate average MSE and MAPE across all predictions
avg_mse <- mean(unlist(mse_list))
avg_mape <- mean(unlist(mape_list))

cat("Average MSE:", avg_mse, "\n")
cat("Average MAPE:", avg_mape, "\n")
```



##### Best Model At Each Time Step
```{r}
# Define training and test periods
train_start_date <- as.Date("2024-01-08")
test_start_date <- as.Date("2024-05-01")
test_end_date <- as.Date("2024-05-15")

# Define dates to loop through in testing
dates <- trading_hours$Date[trading_hours$Date >= test_start_date & trading_hours$Date <= test_end_date]
dates <- dates[!duplicated(dates)]

# Initialize lists to store results
mse_list <- list()
mape_list <- list()
forecasts_arima <- list()
actuals <- list()

# Loop through each test date
for (test_date in dates) {
  # Define training data
  train_data <- trading_hours %>% filter(Date < test_date)
  ts_train <- ts(train_data$Volume, frequency = 8)
  
  # Fit ARIMA model on training data
  fit <- auto.arima(ts_train, seasonal = TRUE)
  summary(fit)
  checkresiduals(fit)

  # Forecast for the test date (8 trading hours)
  forecast_values <- forecast(fit, h = 8)
  
  # Extract actual values for the test date
  actual_values <- trading_hours %>%
    filter(Date == test_date) %>%
    select(Volume) %>%
    unlist()
  
  # Calculate MSE and MAPE
  mse_value <- mse(actual_values, forecast_values$mean)
  mape_value <- mape(actual_values, forecast_values$mean)
  
  # Store results in list
  mse_list[[as.character(test_date)]] <- mse_value
  mape_list[[as.character(test_date)]] <- mape_value
  forecasts_arima[[as.character(test_date)]] <- forecast_values
  actuals[[as.character(test_date)]] <- actual_values

}

# Calculate average MSE and MAPE across all predictions
avg_mse <- mean(unlist(mse_list))
avg_mape <- mean(unlist(mape_list))

cat("Average MSE:", avg_mse, "\n")
cat("Average MAPE:", avg_mape, "\n")
```


### Plotting Predictions
```{r}
# Combine all forecasts and actuals into one dataframe for plotting
all_forecasts_arima <- data.frame(DateTime = as.POSIXct("1900-01-01 09:00:00"),
                            Forecast = -100000,
                            Actual = -10000)

for (test_date in dates)
{
  forecast_values <- forecasts[[as.character(test_date)]]
  actual_values <- actuals[[as.character(test_date)]]
  hours <- seq.POSIXt(from = as.POSIXct(paste(as.Date(test_date), "09:00:00")),
                      by = "hour", length.out = 8)
  
  temp_df <- data.frame(DateTime = hours,
                        Forecast = forecast_values$mean,
                        Actual = actual_values)
  
  all_forecasts_arima <- rbind(all_forecasts_arima, temp_df)
}

all_forecasts_arima = all_forecasts_arima[-1,] # Remove arbitrary first entry


# Plot combined forecast vs actual - no historical data
plot(all_forecasts_arima$Actual, type = 'l',
     col = 'black', ylim = range(all_forecasts_arima$Forecast, all_forecasts_arima$Actual), xlab = "DateTime", ylab = "Volume", main = "Forecasted vs Actual Trading Volume")
lines( all_forecasts_arima$Forecast, col = 'red')
legend("topright", legend = c("Actual", "Forecast"),
       col = c("black", "red"), lty = 1)


# Plot combined forecast vs actual - with historical data
start_index = length(trading_hours$Volume)+1
end_index = length(trading_hours$Volume)+length(all_forecasts_arima$Actual)

plot(trading_hours$Volume, type = 'l',
     xlab = "DateTime", ylab = "Volume",
     main = "Forecasted vs Actual Trading Volume",
     xlim = range(500:end_index))
lines(start_index:end_index, all_forecasts_arima$Actual, type = 'l',
     col = 'black', ylim = range(all_forecasts_arima$Forecast, all_forecasts_arima$Actual))
lines(start_index:end_index, all_forecasts_arima$Forecast, col = 'red')
legend("topright", legend = c("Actual", "Forecast"),
       col = c("black", "red"), lty = 1)


```



### VWAP Predictions
Forecasted VWAP is very tight to actual VWAP - generally within plus/minus 5bps (with the exception of the first day which was at 20bps, which corresponded to a difference in absolute dollars of $0.93).

```{r}
# Combine forecasted volumes with pricing data and save into new dataframe
vwap <- merge(all_forecasts, trading_hours, by.x="DateTime", by.y="Timestamp", all.x = TRUE)


# Calculate predicted and actual trade amounts
vwap <- vwap %>%
  mutate(PredTradeAmt = Forecast * close,
         ActualTradeAmt = Actual * close)


# Calculate VWAP for Each Day
VWAPforecast <- vwap %>%
  group_by(Date) %>%
  summarize(PredVWAP = sum(PredTradeAmt, na.rm = TRUE) / sum(Forecast, na.rm = TRUE),
            ActualVWAP = sum(ActualTradeAmt, na.rm = TRUE) / sum(Actual, na.rm = TRUE),
            AvgPrice = mean(close, na.rm = TRUE),
            PriceVol = sd(close, na.rm = TRUE))

VWAPforecast <- VWAPforecast %>%
  mutate(ErrorPct = (PredVWAP - ActualVWAP) / AvgPrice * 100,
         ErrorBps = ErrorPct*100)


# Calculate Naive VWAP estimates
VWAPforecast$NaiveVWAP1 = lag(VWAPforecast$ActualVWAP) # use yesterday's vwap
VWAPforecast$NaiveVWAP2 = rollmean(VWAPforecast$ActualVWAP, 3, na.pad = TRUE,
                                   align = "right") # rolling average


VWAPforecast <- VWAPforecast %>%
  mutate(NaiveErrorPct1 = (NaiveVWAP1 - ActualVWAP) / AvgPrice * 100,
         NaiveErrorBps1 = NaiveErrorPct1*100,
         NaiveErrorPct2 = (NaiveVWAP2 - ActualVWAP) / AvgPrice * 100,
         NaiveErrorBps2 = NaiveVWAP2*100)


# Plot VWAP error percentage on the LHS y-axis and price volatility on RHS y-axis
plot(VWAPforecast$Date,
     VWAPforecast$ErrorPct,
     type = 'l', col = 'firebrick1',
     main = 'VWAP Forecast Error Percentage',
     ylab = 'Error (%)', xlab = 'Date', ylim = range(-1.5, 0.2))
lines(VWAPforecast$Date, VWAPforecast$NaiveErrorPct1, col = "darkorange")
lines(VWAPforecast$Date, VWAPforecast$NaiveErrorPct2, col = "darkorange3")
legend("bottomright", legend = c("VWAP Error (%)", "Naive Strategies Error (%)"), col = c("firebrick1", "darkorange"), lty = 1, cex = 0.5)

abline(h = 0, col = "pink", lty = 2)

par(new = TRUE)
plot(VWAPforecast$Date,
     VWAPforecast$PriceVol,
     type = 'l', col = 'darkblue', axes = FALSE, xlab = '', ylab = '',
     ylim = range(0, 2.5))
axis(side = 4)
mtext('Price Volatility', side = 4, line = 3)
legend("bottomright", legend = c("VWAP Error (%)", "Naive Strategies Error (%)", "Price Volatility"), col = c("firebrick1", "darkorange", "darkblue"), lty = 1, cex = 0.5)


abline(h = 0, col = "lightblue", lty = 2)

```

